{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4368ea-3569-44db-990d-f2bc4ced8250",
   "metadata": {},
   "source": [
    "# Exercise 3: More Advanced AD with Convolutional Auto-Encoders, Non-Standard Losses, And Generative Adversarial Network Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10933f-724b-4837-90f1-81494e1effd8",
   "metadata": {},
   "source": [
    "### Goals of the Exercise\n",
    "\n",
    "- Make a 2D convolutional autoencoder for events\n",
    "- Explore some non-standard losses for 2D images/autoencoders\n",
    "- Create a Generative Adversarial Network for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aff670-c1f8-4d6d-bf68-5f832fd0fc29",
   "metadata": {},
   "source": [
    "### More Anomaly Detection With Autoencoders\n",
    "\n",
    "A very common form of data in particle physics (and everything else) is images. 2D maps of the visual of something. There are, of course, autoencoders for this, \"convolutional autoencoders\", that use the same filter based features as a traditional image classifier convolutional neural network.\n",
    "\n",
    "Very often, data comes in 2D grids (especially for something like a detector or calorimeter), or a 2D image can be made by imposing a grid based structure on spatial data (note: this is acutally a bit non-ideal as it can lead to sparse data representations, and a whole lot of math on a whole lot of nothing, a problem that graph auto-encoders in the next exercise solve).\n",
    "\n",
    "at this point, you know the drill, we're going to make some auto-encoders for this, and see how they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f02ca4-8fbe-4202-a06a-d085fb508949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:01:23.770912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749830486.508358 1777645 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749830487.346805 1777645 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749830493.120386 1777645 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749830493.120448 1777645 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749830493.120454 1777645 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749830493.120459 1777645 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-13 11:01:33.379857: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69954</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m69954\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65013</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m65013\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88923</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m88923\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204360</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m204360\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m999\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "\n",
    "from rich.console import Console\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "console = Console()\n",
    "\n",
    "def load_data(file_path: str, limit_entries: int = -1) -> np.array:\n",
    "    with h5py.File(file_path) as the_file:\n",
    "        data = np.array(the_file['event_image_data'])[:limit_entries]\n",
    "    return data\n",
    "\n",
    "nprng = np.random.default_rng(42)\n",
    "\n",
    "#Perform random phi rotations on a dataset.\n",
    "#Assumes phi index per example is the first index\n",
    "def random_phi_rotations(the_data:np.array, max_shift: int =8) -> np.array:\n",
    "    new_examples = []\n",
    "    for example in the_data:\n",
    "        shift_value = nprng.integers(-max_shift, max_shift+1)\n",
    "        phi_shifted_example = np.roll(example, axis=0, shift=shift_value)\n",
    "        new_examples.append(phi_shifted_example)\n",
    "    new_examples = np.array(new_examples)\n",
    "    return new_examples\n",
    "\n",
    "#perform random eta reflections on a dataset\n",
    "#Assume eta index per example is the second index\n",
    "def random_eta_reflections(the_data: np.array)->np.array:\n",
    "    new_examples = []\n",
    "    for example in the_data:\n",
    "        if nprng.random() >= 0.5:\n",
    "            new_example = example[:, ::-1]\n",
    "        else:\n",
    "            new_example = example\n",
    "        new_examples.append(new_example)\n",
    "    new_examples = np.array(new_examples)\n",
    "    return new_examples\n",
    "\n",
    "zerobias_data = random_eta_reflections(random_phi_rotations(load_data('data/advanced_files/ZeroBiasAdvancedData.h5')))\n",
    "\n",
    "console.print(zerobias_data.shape)\n",
    "\n",
    "jetht_data = random_eta_reflections(random_phi_rotations(load_data('data/advanced_files/JetHTAdvancedData.h5')))\n",
    "\n",
    "console.print(jetht_data.shape)\n",
    "\n",
    "ttbar_data = random_eta_reflections(random_phi_rotations(load_data('data/advanced_files/TTBarAdvancedData.h5')))\n",
    "\n",
    "console.print(ttbar_data.shape)\n",
    "\n",
    "softqcd_data = random_eta_reflections(random_phi_rotations(load_data('data/advanced_files/SoftQCDAdvancedData.h5')))\n",
    "\n",
    "console.print(softqcd_data.shape)\n",
    "\n",
    "radion_data = random_eta_reflections(random_phi_rotations(load_data('data/advanced_files/RadionAdvancedData.h5')))\n",
    "\n",
    "console.print(radion_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2057bf-9328-48b1-905a-42934a9412ad",
   "metadata": {},
   "source": [
    "The data I have provided here is a $16\\times16$ grid of all reconstructed CMS jets, electrons, photons, muons and taus. The features, per grid cell are:\n",
    "\n",
    "0. $p_{T}$\n",
    "1. $\\phi$\n",
    "2. $\\eta$\n",
    "3. $m$\n",
    "4. A simple code to denote what type of object it is. 1 for jet, 2 for electron, 3 for photon, 4 for muon, 5 for tau.\n",
    "\n",
    "I have also done some dataset augmentation. I have randomly rotated each image in phi so that our autoencoder does not become too dependent on a specific angular setup. It, and physics should not be dependent on that. I have also randomly reflected some examples across eta. The physics here is dependent on eta, but not on the reflection, and the autoencoder should be invariant to that as well.\n",
    "\n",
    "We're going to make a convolutional 2D auto-encoder. There are a lot of things one can do to potentially tune and make an auto-encoder like this. This section is going to be a bit more free-form and I am going to encourage you to try playing around with a bunch of them.\n",
    "\n",
    "Some ideas to look at:\n",
    "- In addition to the latent space _size_ consider whether the latent space is _flat_. One could, in theory completely flatten out the latent space encoding via a `Flatten` layer... or via other methods with less location dependence like Global Pooling. Check how that works in the loss, and for anomaly detection. If you don't flatten it, you can instead maintain a 2D structure, but reduce the amount of information available, and later expand it outward again. Try that, alongside things like max or average pooling.\n",
    "- Some may be wondering \"how do I go from 2D data to a smaller or flat latent space, then back out?\" [keras has reshape layers](https://keras.io/api/layers/reshaping_layers/reshape/) that can allow you to make your completely flat data 2D (or any other shape) again. If you're wondering how to go from a smaller 2D image to a larger one, a simple method is [upsampling](https://keras.io/api/layers/reshaping_layers/up_sampling2d/) which will take a cell and duplicate it next to itself. A likely better solution are [transpose convolutional layers](https://keras.io/api/layers/convolution_layers/convolution2d_transpose/), which behave as a convolutional layer, but in reverse, becoming in effect, learnable upsampling\n",
    "- Convolutional layers have a kernel size, i.e. how many cells worth of features in each direction it uses in its filter creation. Play around with the size of those and see if it makes a difference.\n",
    "- Similarly, Convolutional layers can have stride, i.e. how many cells it skips when it makes another filter calculation. Do be aware, this will change the shape when you use stride\n",
    "- Convolutional neural networks can also have padding, typically \"valid\" padding, only using filled cells (this will also change the output image size), or \"same\" padding (the image is padded with empty cells until the output image would be the same size as the original input image. Play around with those and see where it goes.\n",
    "\n",
    "I'd like to hear from some people what the best overall 2D convolutional auto-encoder they got was, in terms of ROC-AUC on both the JetHT dataset, and on the $t\\bar{t}$ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214e96f8-1e55-4ec8-9030-84e497d36f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,005</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │            \u001b[38;5;34m20\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m3,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m3,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m41,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │         \u001b[38;5;34m4,005\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,961</span> (242.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,961\u001b[0m (242.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,743</span> (241.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,743\u001b[0m (241.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218</span> (872.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m218\u001b[0m (872.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2427 - mae: 0.1145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:10:24.007117: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.16 = (f32[7,32,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[7,16,8,8]{3,2,1,0} %bitcast.866, f32[32,16,3,3]{3,2,1,0} %bitcast.873, f32[32]{0} %bitcast.875), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 1.2429 - mae: 0.1145 - val_loss: 2.5015 - val_mae: 0.0343\n",
      "Epoch 2/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.5567 - mae: 0.0502 - val_loss: 2.4039 - val_mae: 0.0316\n",
      "Epoch 3/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.5545 - mae: 0.0460 - val_loss: 2.3900 - val_mae: 0.0331\n",
      "Epoch 4/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.1039 - mae: 0.0393 - val_loss: 2.3894 - val_mae: 0.0317\n",
      "Epoch 5/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.5948 - mae: 0.0394 - val_loss: 2.3754 - val_mae: 0.0291\n",
      "Epoch 6/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.3751 - mae: 0.0400 - val_loss: 2.4168 - val_mae: 0.0309\n",
      "Epoch 7/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.2089 - mae: 0.0376 - val_loss: 2.3658 - val_mae: 0.0307\n",
      "Epoch 8/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.1112 - mae: 0.0420 - val_loss: 2.3554 - val_mae: 0.0333\n",
      "Epoch 9/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.7232 - mae: 0.0437 - val_loss: 2.3562 - val_mae: 0.0291\n",
      "Epoch 10/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.8848 - mae: 0.0428 - val_loss: 2.3872 - val_mae: 0.0299\n",
      "Epoch 11/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.5405 - mae: 0.0420 - val_loss: 2.3182 - val_mae: 0.0314\n",
      "Epoch 12/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4637 - mae: 0.0451 - val_loss: 2.2940 - val_mae: 0.0330\n",
      "Epoch 13/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.9243 - mae: 0.0445 - val_loss: 2.3138 - val_mae: 0.0328\n",
      "Epoch 14/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.0594 - mae: 0.0477 - val_loss: 2.3390 - val_mae: 0.0347\n",
      "Epoch 15/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.2883 - mae: 0.0440 - val_loss: 2.1764 - val_mae: 0.0362\n",
      "Epoch 16/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.6811 - mae: 0.0485 - val_loss: 2.1262 - val_mae: 0.0359\n",
      "Epoch 17/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.3159 - mae: 0.0467 - val_loss: 2.1745 - val_mae: 0.0331\n",
      "Epoch 18/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.3822 - mae: 0.0492 - val_loss: 2.2268 - val_mae: 0.0336\n",
      "Epoch 19/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4940 - mae: 0.0485 - val_loss: 2.1274 - val_mae: 0.0347\n",
      "Epoch 20/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.8678 - mae: 0.0522 - val_loss: 2.0269 - val_mae: 0.0341\n",
      "Epoch 21/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.3024 - mae: 0.0530 - val_loss: 1.9637 - val_mae: 0.0369\n",
      "Epoch 22/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.6194 - mae: 0.0542 - val_loss: 2.0613 - val_mae: 0.0393\n",
      "Epoch 23/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.1449 - mae: 0.0504 - val_loss: 2.0119 - val_mae: 0.0407\n",
      "Epoch 24/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.0614 - mae: 0.0522 - val_loss: 2.2102 - val_mae: 0.0338\n",
      "Epoch 25/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4593 - mae: 0.0564 - val_loss: 2.0926 - val_mae: 0.0379\n",
      "Epoch 26/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.6422 - mae: 0.0552 - val_loss: 2.0074 - val_mae: 0.0407\n",
      "Epoch 27/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.9031 - mae: 0.0601 - val_loss: 2.1919 - val_mae: 0.0382\n",
      "Epoch 28/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.1573 - mae: 0.0561 - val_loss: 1.9295 - val_mae: 0.0355\n",
      "Epoch 29/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.6173 - mae: 0.0566 - val_loss: 1.8169 - val_mae: 0.0412\n",
      "Epoch 30/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4174 - mae: 0.0567 - val_loss: 2.1653 - val_mae: 0.0353\n",
      "Epoch 31/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4381 - mae: 0.0544 - val_loss: 2.0285 - val_mae: 0.0400\n",
      "Epoch 32/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.5693 - mae: 0.0569 - val_loss: 2.1813 - val_mae: 0.0425\n",
      "Epoch 33/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4854 - mae: 0.0598 - val_loss: 1.9193 - val_mae: 0.0389\n",
      "Epoch 34/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 2.0934 - mae: 0.0636 - val_loss: 2.2215 - val_mae: 0.0356\n",
      "Epoch 35/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 0.9086 - mae: 0.0545 - val_loss: 2.2940 - val_mae: 0.0344\n",
      "Epoch 36/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 1.4316 - mae: 0.0600 - val_loss: 2.2086 - val_mae: 0.0416\n",
      "Epoch 37/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.7304 - mae: 0.0655 - val_loss: 2.2568 - val_mae: 0.0369\n",
      "Epoch 38/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.4960 - mae: 0.0618 - val_loss: 1.8962 - val_mae: 0.0407\n",
      "Epoch 39/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 1.6027 - mae: 0.0618 - val_loss: 2.1740 - val_mae: 0.0369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9bacc705e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Exercise: Make a 2D convolutional auto-encoder, and try changing some of the parameters\n",
    "#\n",
    "\n",
    "zerobias_train, zerobias_testval = train_test_split(\n",
    "    zerobias_data,\n",
    "    test_size=0.4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "zerobias_val, zerobias_test = train_test_split(\n",
    "    zerobias_testval,\n",
    "    test_size=0.2/0.4,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "conv_ae = keras.Sequential([\n",
    "    #\n",
    "    # encoder\n",
    "    #\n",
    "    keras.layers.Input(shape=zerobias_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=7,\n",
    "        padding='same',\n",
    "        activation='leaky_relu',\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    #Size is now 8 x 8, 16 filters\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='leaky_relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.GlobalMaxPooling2D(),\n",
    "    #\n",
    "    # Final latent space size and shape: 32 flat entries\n",
    "    #\n",
    "    #\n",
    "    # decoder\n",
    "    #\n",
    "    keras.layers.Dense(4*4*8, activation='leaky_relu'),\n",
    "    keras.layers.Reshape((4,4,8)), #new shape is 4 x 4 with 8 features\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    #keras.layers.Conv2DTranspose(16, kernel_size=2, strides=2, activation='leaky_relu'), # new shape is 8 x 8 with 16 features\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=5, strides=1, activation='leaky_relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    #keras.layers.Conv2DTranspose(32, kernel_size=2, strides=2, activation='leaky_relu'), # new shape is 16 x 16 with 32 features\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=9, strides=1, activation='leaky_relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    keras.layers.Conv2D(5, kernel_size=5, padding='same'), # final shape is 16 x 16 with 5 features\n",
    "])\n",
    "\n",
    "conv_ae.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae'],\n",
    ")\n",
    "conv_ae.summary()\n",
    "\n",
    "conv_ae.fit(\n",
    "    x=zerobias_data,\n",
    "    y=zerobias_data,\n",
    "    validation_data=(zerobias_val, zerobias_val),\n",
    "    epochs=200,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efc9475-f6a9-453c-a49e-8aaae57ee415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "\u001b[1m2778/2779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:23:15.037781: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.16 = (f32[27,32,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,16,8,8]{3,2,1,0} %bitcast.700, f32[32,16,3,3]{3,2,1,0} %bitcast.707, f32[32]{0} %bitcast.709), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-13 11:23:15.149781: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.19 = (f32[27,5,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,32,16,16]{3,2,1,0} %bitcast.905, f32[5,32,5,5]{3,2,1,0} %bitcast.912, f32[5]{0} %bitcast.914), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2779/2779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m2011/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:23:21.630568: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.16 = (f32[21,32,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,16,8,8]{3,2,1,0} %bitcast.700, f32[32,16,3,3]{3,2,1,0} %bitcast.707, f32[32]{0} %bitcast.709), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-13 11:23:21.742732: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.19 = (f32[21,5,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,32,16,16]{3,2,1,0} %bitcast.905, f32[5,32,5,5]{3,2,1,0} %bitcast.912, f32[5]{0} %bitcast.914), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "\u001b[1m6383/6387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:23:38.806666: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.16 = (f32[8,32,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,16,8,8]{3,2,1,0} %bitcast.700, f32[32,16,3,3]{3,2,1,0} %bitcast.707, f32[32]{0} %bitcast.709), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-13 11:23:38.905390: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.19 = (f32[8,5,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,16,16]{3,2,1,0} %bitcast.905, f32[5,32,5,5]{3,2,1,0} %bitcast.912, f32[5]{0} %bitcast.914), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6387/6387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9b3063bca0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Exercise: Evaluate the model you made in the previous section\n",
    "#\n",
    "\n",
    "def make_roc(background_scores, signal_scores, legend_label) -> None:\n",
    "    y_true = np.append(\n",
    "        np.ones(len(signal_scores)),\n",
    "        np.zeros(len(background_scores)),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    y_pred = np.append(\n",
    "        signal_scores,\n",
    "        background_scores,\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f'{legend_label} ROC (AUC: {auc:.4})'\n",
    "    )\n",
    "\n",
    "zerobias_predictions = conv_ae.predict(zerobias_test)\n",
    "ttbar_predictions = conv_ae.predict(ttbar_data)\n",
    "jetht_predictions = conv_ae.predict(jetht_data)\n",
    "softqcd_predictions = conv_ae.predict(softqcd_data)\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_pred-y_true)**2, axis=(1,2,3))\n",
    "\n",
    "zerobias_score = np.array(mean_squared_error(zerobias_test, zerobias_predictions))\n",
    "ttbar_score = np.array(mean_squared_error(ttbar_data, ttbar_predictions))\n",
    "jetht_score = np.array(mean_squared_error(jetht_data, jetht_predictions))\n",
    "softqcd_score = np.array(mean_squared_error(softqcd_data, softqcd_predictions))\n",
    "\n",
    "make_roc(zerobias_score, ttbar_score, legend_label=r'$t\\bar{t}$')\n",
    "make_roc(zerobias_score, jetht_score, legend_label=r'Jet HT')\n",
    "make_roc(zerobias_score, softqcd_score, legend_label=r'Soft QCD')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfedd3-6831-4802-a2e1-de9d60a4cb4e",
   "metadata": {},
   "source": [
    "### Esoteric Losses\n",
    "\n",
    "This section is also a little more freeform. I just wanted to take some time to introduce other loss functions than Mean Squared Error here. Mean Squared Error is not a bad loss, and should be your first stop in checking things when making reconstruction losses, but it also can reward \"peak memorization\" and out of set reconstruction if you aren't careful. For images like we're working with, you do have other options. These are things I am experimenting around with, so I figured it might be interesting for you all to take a look at them as well and see how they work for this exercise. No guaratees from my side that these will be suitable or usable. It is good practice to try implementing your own loss functions though, because the loss function really does shape the behavior of a neural network as much as the layers you put in it you may be called to really try exploring that as much as you would trying to put in more or fancier layers.\n",
    "\n",
    "#### Huber Loss\n",
    "\n",
    "The [Huber Loss](https://keras.io/api/losses/regression_losses/#huber-class) comes from the [Huber Function](https://en.wikipedia.org/wiki/Huber_loss) a piecewise combination of Mean Absolute Error and Mean Squared Error. The idea behind it is to try and prevent giving outliers outsize importance by the squared portion of Mean Squared Error. It applies Mean Absolute Error to get most values pretty close but not give large outliers outsized importance, and then Mean Squared Error closer to 0 so that it hones in the accuracy of those values that form the non-outlier elements. Keras provides an implementation of this loss for us to use. \n",
    "\n",
    "Why would you try to be impervious to outliers in our anomaly detection autoencoder? Well, if it gives a larger loss to outliers, and learns to reconstruct them better to minimize it, we're baking in the ability to reconstruct anomlies with our loss function!\n",
    "\n",
    "#### Normalized Cross Correlation\n",
    "\n",
    "Normalized Cross Correlation is a metric between two signals or images (it doesn't necessarily have to be 2D) that measures the similarity of them, regardless of the amplitudes of the images. It rewards structural similarity over magnitude similarity. You can read a bit more [here](https://en.wikipedia.org/wiki/Cross-correlation#Zero-normalized_cross-correlation_(ZNCC)), but in general, think of it as a function that is close to 1 if the two patterns have the same shape (but not necessarily the same overall amplitude).\n",
    "\n",
    "It can be calculated like so:\n",
    "\n",
    "$\\frac{\\sum{((x-\\bar{x}) * (\\hat{x}-\\bar{\\bar{x}}))}}{\\sqrt{\\sum{x-\\bar{x}}^{2}} * \\sqrt{\\sum{\\hat{x}-\\bar{\\hat{x}}}^{2}}}$\n",
    "\n",
    "where $\\hat{x}$ is our predicted value, and $x$ is the true value.\n",
    "\n",
    "Since this grows with similarity instead of decreasing (i.e. it measures accuracy not error), but is bounded by 1.0, we can simply do $1-NCC$ as the actual loss function.\n",
    "\n",
    "#### Structural Similarity Index\n",
    "\n",
    "[Structural Similarity Index](https://en.wikipedia.org/wiki/Structural_similarity_index_measure) is a measure used in image transmission (television notably) to determine how similar a transmitted image looks to an observer. Rather than compare pizel by pizel though, it uses a lot of filtering and local structures to try and make a similarity judgement, even if the overall pixel values differ (In $MSE$ or $NCC$, an image shifted right by a few pixels could have a huge loss, by in structural similarity, it looks similar because the it maintains the variances and means roughly). The math behind it is a little more complicated, but nothing too terrible.\n",
    "\n",
    "Tensorflow as part of the various image processing utilities it has, has an implementation of this, but to use it, it requires a filter size for the rough sizes of structures to look out for, and a max value difference between pixels.\n",
    "\n",
    "#### Hybrid Losses\n",
    "\n",
    "Once you get used to using custom losses, nothing is also preventing you from _blending_ loss functions. $\\alpha*Loss_{1} + (1.0-\\alpha)*Loss_{2}$.\n",
    "\n",
    "I have included loss functions below for you to try out and look at. You may even notice that $MSE$ improves alongside some of these losses, or nothing prevents the two from being highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b738ec21-92d4-40a4-a469-394d1137c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for you to use\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "huber_loss = keras.losses.Huber(delta=1.0)\n",
    "huber_metric = keras.losses.Huber(delta=1.0, reduction=None) # for use in evaluation later\n",
    "\n",
    "def normalized_cross_correlation_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    "    x_mean = tf.reshape(tf.reduce_mean(y_true, axis=(1,2,3)), [-1,1,1,1])\n",
    "    x_hat_mean = tf.reshape(tf.reduce_mean(y_pred, axis=(1,2,3)), [-1,1,1,1])\n",
    "\n",
    "    x_minus_mean = y_true-x_mean\n",
    "    x_hat_minus_mean = y_pred-x_hat_mean\n",
    "\n",
    "    num = tf.reduce_sum(x_minus_mean * x_hat_minus_mean, axis=(1,2,3))\n",
    "    denom = tf.math.sqrt(tf.reduce_sum(x_minus_mean**2, axis=(1,2,3)))*tf.math.sqrt(tf.reduce_sum(x_hat_minus_mean**2, axis=(1,2,3))) \n",
    "\n",
    "    return 1.0 - (num/(denom+1e-6))\n",
    "\n",
    "def ssim_loss_fn(y_true, y_pred, filter_size=5, max_val=1.0):\n",
    "    return 1.0 - tf.image.ssim(\n",
    "        tf.cast(y_true, dtype=tf.float64),\n",
    "        tf.cast(y_pred, dtype=tf.float64),\n",
    "        filter_size=filter_size,\n",
    "        max_val=max_val\n",
    "    )\n",
    "\n",
    "max_val_difference = np.max(zerobias_train) - np.min(zerobias_train)\n",
    "\n",
    "ssim_loss = lambda y_true, y_pred: ssim_loss_fn(y_true, y_pred, filter_size=5, max_val=max_val_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af467458-35fb-46a0-ba4f-3db2acf17694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,976</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,005</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │            \u001b[38;5;34m20\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m3,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,432\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m82,976\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │         \u001b[38;5;34m4,005\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,713</span> (416.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,713\u001b[0m (416.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,463</span> (415.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,463\u001b[0m (415.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250</span> (1000.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m250\u001b[0m (1000.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0359 - mae: 0.0902 - mse: 1.7623 - val_loss: 0.0150 - val_mae: 0.0231 - val_mse: 2.4827\n",
      "Epoch 2/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0149 - mae: 0.0264 - mse: 1.4665 - val_loss: 0.0148 - val_mae: 0.0215 - val_mse: 2.4782\n",
      "Epoch 3/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0146 - mae: 0.0218 - mse: 2.4623 - val_loss: 0.0146 - val_mae: 0.0187 - val_mse: 2.4747\n",
      "Epoch 4/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0144 - mae: 0.0195 - mse: 1.7642 - val_loss: 0.0146 - val_mae: 0.0173 - val_mse: 2.4748\n",
      "Epoch 5/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0142 - mae: 0.0178 - mse: 1.4680 - val_loss: 0.0146 - val_mae: 0.0175 - val_mse: 2.4742\n",
      "Epoch 6/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0147 - mae: 0.0181 - mse: 1.9125 - val_loss: 0.0145 - val_mae: 0.0183 - val_mse: 2.4732\n",
      "Epoch 7/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0145 - mae: 0.0188 - mse: 1.9480 - val_loss: 0.0143 - val_mae: 0.0186 - val_mse: 2.4644\n",
      "Epoch 8/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0141 - mae: 0.0200 - mse: 1.1339 - val_loss: 0.0139 - val_mae: 0.0178 - val_mse: 2.4554\n",
      "Epoch 9/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0137 - mae: 0.0194 - mse: 1.1869 - val_loss: 0.0137 - val_mae: 0.0174 - val_mse: 2.4537\n",
      "Epoch 10/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0135 - mae: 0.0194 - mse: 1.4848 - val_loss: 0.0136 - val_mae: 0.0174 - val_mse: 2.4466\n",
      "Epoch 11/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0137 - mae: 0.0196 - mse: 1.8158 - val_loss: 0.0133 - val_mae: 0.0168 - val_mse: 2.4416\n",
      "Epoch 12/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0133 - mae: 0.0194 - mse: 1.5446 - val_loss: 0.0132 - val_mae: 0.0169 - val_mse: 2.4387\n",
      "Epoch 13/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0194 - mse: 1.5007 - val_loss: 0.0129 - val_mae: 0.0166 - val_mse: 2.4318\n",
      "Epoch 14/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0194 - mse: 1.1823 - val_loss: 0.0129 - val_mae: 0.0175 - val_mse: 2.4319\n",
      "Epoch 15/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0130 - mae: 0.0192 - mse: 1.3644 - val_loss: 0.0128 - val_mae: 0.0168 - val_mse: 2.4300\n",
      "Epoch 16/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0196 - mse: 3.0378 - val_loss: 0.0128 - val_mae: 0.0167 - val_mse: 2.4290\n",
      "Epoch 17/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0190 - mse: 1.2750 - val_loss: 0.0128 - val_mae: 0.0167 - val_mse: 2.4297\n",
      "Epoch 18/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0129 - mae: 0.0191 - mse: 1.7549 - val_loss: 0.0127 - val_mae: 0.0166 - val_mse: 2.4283\n",
      "Epoch 19/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0130 - mae: 0.0192 - mse: 2.5927 - val_loss: 0.0126 - val_mae: 0.0164 - val_mse: 2.4231\n",
      "Epoch 20/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0187 - mse: 1.3623 - val_loss: 0.0127 - val_mae: 0.0176 - val_mse: 2.4277\n",
      "Epoch 21/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0129 - mae: 0.0193 - mse: 1.5811 - val_loss: 0.0126 - val_mae: 0.0181 - val_mse: 2.4235\n",
      "Epoch 22/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0192 - mse: 1.5335 - val_loss: 0.0125 - val_mae: 0.0169 - val_mse: 2.4200\n",
      "Epoch 23/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0194 - mse: 1.9970 - val_loss: 0.0123 - val_mae: 0.0166 - val_mse: 2.4161\n",
      "Epoch 24/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0194 - mse: 1.5037 - val_loss: 0.0122 - val_mae: 0.0171 - val_mse: 2.4140\n",
      "Epoch 25/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0193 - mse: 1.4134 - val_loss: 0.0122 - val_mae: 0.0164 - val_mse: 2.4119\n",
      "Epoch 26/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0193 - mse: 1.2489 - val_loss: 0.0120 - val_mae: 0.0160 - val_mse: 2.4104\n",
      "Epoch 27/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0193 - mse: 1.4331 - val_loss: 0.0122 - val_mae: 0.0165 - val_mse: 2.4153\n",
      "Epoch 28/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0192 - mse: 1.2227 - val_loss: 0.0121 - val_mae: 0.0168 - val_mse: 2.4117\n",
      "Epoch 29/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0192 - mse: 1.8866 - val_loss: 0.0121 - val_mae: 0.0165 - val_mse: 2.4100\n",
      "Epoch 30/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0190 - mse: 1.4367 - val_loss: 0.0121 - val_mae: 0.0161 - val_mse: 2.4120\n",
      "Epoch 31/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0190 - mse: 1.5521 - val_loss: 0.0119 - val_mae: 0.0157 - val_mse: 2.4067\n",
      "Epoch 32/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0191 - mse: 2.1203 - val_loss: 0.0120 - val_mae: 0.0162 - val_mse: 2.4083\n",
      "Epoch 33/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0192 - mse: 1.6800 - val_loss: 0.0117 - val_mae: 0.0162 - val_mse: 2.4057\n",
      "Epoch 34/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0191 - mse: 1.5716 - val_loss: 0.0119 - val_mae: 0.0155 - val_mse: 2.4089\n",
      "Epoch 35/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0189 - mse: 1.4353 - val_loss: 0.0120 - val_mae: 0.0163 - val_mse: 2.4090\n",
      "Epoch 36/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0189 - mse: 1.2364 - val_loss: 0.0118 - val_mae: 0.0157 - val_mse: 2.4062\n",
      "Epoch 37/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0190 - mse: 2.0938 - val_loss: 0.0117 - val_mae: 0.0161 - val_mse: 2.4032\n",
      "Epoch 38/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0191 - mse: 2.7610 - val_loss: 0.0119 - val_mae: 0.0159 - val_mse: 2.4077\n",
      "Epoch 39/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0192 - mse: 1.8026 - val_loss: 0.0118 - val_mae: 0.0155 - val_mse: 2.4030\n",
      "Epoch 40/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0192 - mse: 1.5854 - val_loss: 0.0116 - val_mae: 0.0160 - val_mse: 2.4011\n",
      "Epoch 41/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0192 - mse: 2.3793 - val_loss: 0.0119 - val_mae: 0.0173 - val_mse: 2.4052\n",
      "Epoch 42/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0189 - mse: 1.7319 - val_loss: 0.0118 - val_mae: 0.0167 - val_mse: 2.4040\n",
      "Epoch 43/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0189 - mse: 1.9623 - val_loss: 0.0116 - val_mae: 0.0156 - val_mse: 2.4018\n",
      "Epoch 44/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0189 - mse: 1.7169 - val_loss: 0.0116 - val_mae: 0.0158 - val_mse: 2.3991\n",
      "Epoch 45/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0189 - mse: 1.5633 - val_loss: 0.0117 - val_mae: 0.0160 - val_mse: 2.4027\n",
      "Epoch 46/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0190 - mse: 2.0086 - val_loss: 0.0116 - val_mae: 0.0153 - val_mse: 2.4001\n",
      "Epoch 47/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0188 - mse: 1.4027 - val_loss: 0.0115 - val_mae: 0.0155 - val_mse: 2.3974\n",
      "Epoch 48/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0190 - mse: 1.5222 - val_loss: 0.0115 - val_mae: 0.0169 - val_mse: 2.3960\n",
      "Epoch 49/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0186 - mse: 1.0729 - val_loss: 0.0117 - val_mae: 0.0158 - val_mse: 2.4019\n",
      "Epoch 50/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0187 - mse: 1.7014 - val_loss: 0.0117 - val_mae: 0.0155 - val_mse: 2.3986\n",
      "Epoch 51/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0185 - mse: 0.9480 - val_loss: 0.0116 - val_mae: 0.0155 - val_mse: 2.3972\n",
      "Epoch 52/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0188 - mse: 1.6134 - val_loss: 0.0115 - val_mae: 0.0157 - val_mse: 2.3961\n",
      "Epoch 53/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0187 - mse: 1.5151 - val_loss: 0.0118 - val_mae: 0.0155 - val_mse: 2.4016\n",
      "Epoch 54/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0186 - mse: 1.2906 - val_loss: 0.0114 - val_mae: 0.0161 - val_mse: 2.3929\n",
      "Epoch 55/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0191 - mse: 1.6903 - val_loss: 0.0115 - val_mae: 0.0153 - val_mse: 2.3942\n",
      "Epoch 56/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0189 - mse: 2.1118 - val_loss: 0.0115 - val_mae: 0.0156 - val_mse: 2.3948\n",
      "Epoch 57/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0189 - mse: 1.9587 - val_loss: 0.0117 - val_mae: 0.0159 - val_mse: 2.3995\n",
      "Epoch 58/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0184 - mse: 1.0798 - val_loss: 0.0119 - val_mae: 0.0158 - val_mse: 2.3968\n",
      "Epoch 59/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0187 - mse: 1.3373 - val_loss: 0.0116 - val_mae: 0.0155 - val_mse: 2.3941\n",
      "Epoch 60/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0188 - mse: 1.3970 - val_loss: 0.0117 - val_mae: 0.0174 - val_mse: 2.3981\n",
      "Epoch 61/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0187 - mse: 1.4823 - val_loss: 0.0113 - val_mae: 0.0155 - val_mse: 2.3826\n",
      "Epoch 62/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0187 - mse: 1.7732 - val_loss: 0.0114 - val_mae: 0.0154 - val_mse: 2.3892\n",
      "Epoch 63/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0184 - mse: 1.6824 - val_loss: 0.0115 - val_mae: 0.0153 - val_mse: 2.3921\n",
      "Epoch 64/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0185 - mse: 1.2598 - val_loss: 0.0118 - val_mae: 0.0162 - val_mse: 2.3996\n",
      "Epoch 65/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0183 - mse: 1.3059 - val_loss: 0.0117 - val_mae: 0.0155 - val_mse: 2.3978\n",
      "Epoch 66/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0185 - mse: 2.5419 - val_loss: 0.0114 - val_mae: 0.0157 - val_mse: 2.3863\n",
      "Epoch 67/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0185 - mse: 1.2652 - val_loss: 0.0118 - val_mae: 0.0153 - val_mse: 2.3955\n",
      "Epoch 68/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0186 - mse: 1.7260 - val_loss: 0.0118 - val_mae: 0.0161 - val_mse: 2.3951\n",
      "Epoch 69/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0119 - mae: 0.0186 - mse: 1.6792 - val_loss: 0.0116 - val_mae: 0.0152 - val_mse: 2.3914\n",
      "Epoch 70/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0118 - mae: 0.0184 - mse: 1.8256 - val_loss: 0.0114 - val_mae: 0.0150 - val_mse: 2.3864\n",
      "Epoch 71/200\n",
      "\u001b[1m2187/2187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0188 - mse: 2.8402 - val_loss: 0.0116 - val_mae: 0.0152 - val_mse: 2.3885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9baca56520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Exercise: Make a seperate model with a different loss function\n",
    "#\n",
    "\n",
    "new_ae = keras.Sequential([\n",
    "    #\n",
    "    # encoder\n",
    "    #\n",
    "    keras.layers.Input(shape=zerobias_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=7,\n",
    "        padding='same',\n",
    "        activation='leaky_relu',\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    #Size is now 8 x 8, 16 filters\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='leaky_relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.GlobalMaxPooling2D(),\n",
    "    #\n",
    "    # Final latent space size and shape: 32 flat entries\n",
    "    #\n",
    "    #\n",
    "    # decoder\n",
    "    #\n",
    "    keras.layers.Dense(4*4*8, activation='leaky_relu'),\n",
    "    keras.layers.Reshape((4,4,8)), #new shape is 4 x 4 with 8 features\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    #keras.layers.Conv2DTranspose(16, kernel_size=2, strides=2, activation='leaky_relu'), # new shape is 8 x 8 with 16 features\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=5, strides=1, activation='leaky_relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    #keras.layers.Conv2DTranspose(32, kernel_size=2, strides=2, activation='leaky_relu'), # new shape is 16 x 16 with 32 features\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=9, strides=1, activation='leaky_relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    keras.layers.Conv2D(5, kernel_size=5, padding='same'), # final shape is 16 x 16 with 5 features\n",
    "])\n",
    "\n",
    "new_ae.compile(\n",
    "    optimizer='adam',\n",
    "    loss=huber_loss,\n",
    "    metrics=['mse', 'mae'],\n",
    ")\n",
    "new_ae.summary()\n",
    "\n",
    "new_ae.fit(\n",
    "    x=zerobias_data,\n",
    "    y=zerobias_data,\n",
    "    validation_data=(zerobias_val, zerobias_val),\n",
    "    epochs=200,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f289a9-e534-4f49-b238-48f913299412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m2779/2779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m6387/6387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13991</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m13991\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13991</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m13991\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9a7d7ec250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Exercise: Compare this different loss function model to the previous model. Which works better?\n",
    "#\n",
    "\n",
    "new_zerobias_predictions = conv_ae.predict(zerobias_test)\n",
    "new_ttbar_predictions = conv_ae.predict(ttbar_data)\n",
    "new_jetht_predictions = conv_ae.predict(jetht_data)\n",
    "new_softqcd_predictions = conv_ae.predict(softqcd_data)\n",
    "\n",
    "test = huber_metric(zerobias_test, new_zerobias_predictions)\n",
    "console.print(new_zerobias_predictions.shape)\n",
    "console.print(test.shape)\n",
    "\n",
    "new_zerobias_score = np.mean(np.array(huber_metric(zerobias_test, new_zerobias_predictions)), axis=(1,2))\n",
    "new_ttbar_score = np.mean(np.array(huber_metric(ttbar_data, new_ttbar_predictions)), axis=(1,2))\n",
    "new_jetht_score = np.mean(np.array(huber_metric(jetht_data, new_jetht_predictions)), axis=(1,2))\n",
    "new_softqcd_score = np.mean(np.array(huber_metric(softqcd_data, new_softqcd_predictions)), axis=(1,2))\n",
    "\n",
    "make_roc(new_zerobias_score, new_ttbar_score, legend_label=r'$t\\bar{t}$')\n",
    "make_roc(new_zerobias_score, new_jetht_score, legend_label=r'Jet HT')\n",
    "make_roc(new_zerobias_score, new_softqcd_score, legend_label=r'Soft QCD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9c556-3fed-4fb0-977b-fefa7db32d72",
   "metadata": {},
   "source": [
    "### Different Networks for Anomaly Detection: Generative Adversarial Networks\n",
    "Up to this point we have been focusing exclusively on different types of Autoencoder, because they form the most common and easiest to use idea in anomaly detection. They are not the only unsupervised technique in neural networks though, which means they are not the only technique in anomaly detection. The other big kind of network is the \"Generative Adversarial Network\". The idea goes like this: Generative Adversarial Networks actually use a pair of models, the first model is designed to take a bunch of noise/random numbers, and from this, it creates data that looks like the input dataset you are doing unsupervised learning on. The second model is a classifier, and its job is to judge whether the images it has gotten are genuinely from the dataset, or are fakes. The first model is trained to try and fool the second classifier model, the second classifier model is trained to try and find the genuine article and not get fooled.\n",
    "\n",
    "At the end of training both of these models, the classifier then should be relatively picky and serve as a good judge of whether something belongs to the dataset it has seen, or is anomalous.\n",
    "\n",
    "Because the training loop is a bit particular and odd, we can't actually use the standard `fit` function. I will provide the training loop, you provide the models. This training loop is also _very_ slow due to the amount of things that have to go on to get it to work (EDIT: Potentially also some memory issues with this?). It likely will not finish in the time we have. There is probably some optimization of things that happen here to make it a little less \"by hand\", but it should showcase the basic idea, which is what I want you to have. You should know that you can do anomaly detection with other neural networks, and there may even be some upsides to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665b14df-76ac-4c0c-a3ae-bbef36f9a963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8737202d6f7438fb742efb55ff18551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 11:40:56.286464: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[64,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,8,5,5]{3,2,1,0} %bitcast.11344, f32[16,8,3,3]{3,2,1,0} %bitcast.10394, f32[16]{0} %bitcast.11414), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_13_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-13 11:41:00.300455: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[32,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,5,5]{3,2,1,0} %bitcast.11928, f32[16,8,3,3]{3,2,1,0} %bitcast.11935, f32[16]{0} %bitcast.11937), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_6_1/sequential_5_1/conv2d_13_1/convolution\" source_file=\"/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer._make_function.<locals>.one_step_on_data at 0x7f9ba7c653a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer._make_function.<locals>.one_step_on_data at 0x7f9ba5204160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m             gan\u001b[38;5;241m.\u001b[39mtrain_on_batch(noise, y2)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gan\n\u001b[0;32m--> 122\u001b[0m trained_gan \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzerobias_gan_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_coding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#The classifier and generator can be split off into seperate models\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#The classifier can be used for anomaly detection by evaluating on datasets as usual\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#Depending on what you want to do, you can find a use for the generator too.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 119\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(gan, dataset, input_coding_size, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m    117\u001b[0m         classifier\u001b[38;5;241m.\u001b[39mtrainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    118\u001b[0m         gan\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m         \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gan\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:605\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 605\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:228\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    227\u001b[0m     ):\n\u001b[0;32m--> 228\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    911\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    912\u001b[0m   )\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m/afs/hep.wisc.edu/cms/aloeliger/anomalyTriggerWork/ADWorkshop/CMS_OpenData_Exercises/cms_opendata_exercises_env/lib64/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Exercise: Fill in the generator_model and classifier_model\n",
    "#\n",
    "from rich.progress import track\n",
    "\n",
    "#Fill this in\n",
    "#The generator model will need to take some random amount of noise as inputs\n",
    "#But end up in our 16 x 16 with 5 features outputs\n",
    "# I chose a flat input of size 4 * 4 * 2 = 32 noise inputs, that I reshape into 4 x 4 with 2 features\n",
    "generator_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(32,)),\n",
    "    keras.layers.Reshape((4,4,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(4, kernel_size=2, strides=2, activation='leaky_relu'), # 8 x 8 with 4 features\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "    keras.layers.Conv2DTranspose(5, kernel_size=2, strides=2) # 16 x 16 with 5 features\n",
    "])\n",
    "\n",
    "#This will run on the 16 x 16 with 5 features present in zero bias data\n",
    "# or the generator model output\n",
    "classifier_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=zerobias_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(\n",
    "        8,\n",
    "        kernel_size=7,\n",
    "        activation='leaky_relu',\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        16,\n",
    "        kernel_size=3,\n",
    "        activation='leaky_relu',\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SpatialDropout2D(0.2),\n",
    "\n",
    "    keras.layers.GlobalMaxPooling2D(),\n",
    "    keras.layers.Dense(8, activation='leaky_relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "batch_size=32\n",
    "zerobias_gan_dataset = tf.data.Dataset.from_tensor_slices(zerobias_train).shuffle(1000)\n",
    "zerobias_gan_dataset = zerobias_gan_dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "#TF can be a little funny about types it allows in training. Our dataset is double, it wants float\n",
    "#This just quickly converts it\n",
    "def cast_to_tf_float(x):\n",
    "    return tf.cast(x, tf.dtypes.float32)\n",
    "zerobias_gan_dataset = zerobias_gan_dataset.map(cast_to_tf_float)\n",
    "\n",
    "gan = keras.models.Sequential([generator_model, classifier_model])\n",
    "\n",
    "classifier_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "def train_gan(gan, dataset, input_coding_size, n_epochs=5, batch_size=32):\n",
    "    generator, classifier = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        console.print(f'Epoch: {epoch}')\n",
    "        for x_batch in track(dataset):\n",
    "            #Random noise to feed to the generator model\n",
    "            noise = tf.random.normal(shape=[batch_size, input_coding_size])\n",
    "            #First we train the classifier model by itself. To do that, we need some generated images\n",
    "            #We generate that with the generator model and some noise. These won't be good at first\n",
    "            #But we'll train the generator to fool the classifier soon\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            #concatenate our fake images and genuine images together\n",
    "            x_fake_and_real = tf.concat([generated_images, x_batch], axis=0)\n",
    "            #Now we need our labels, beause we're training the classifier, the noise images should be 0, the genuine should be 1\n",
    "            y1 = tf.concat([\n",
    "                    tf.zeros((batch_size,)),\n",
    "                    tf.ones((batch_size,)),\n",
    "                ],\n",
    "                axis=0\n",
    "            )\n",
    "            # Note, we could also provide labels that are not-directly 0 or 1, but close, like so: \n",
    "            # y1 = tf.concat(                                                                                                                            \n",
    "            #   [                                                                                                                                      \n",
    "            #    tf.math.abs(                                                                                                                       \n",
    "            #       tf.random.normal(                                                                                                              \n",
    "            #          mean=0.0,                                                                                                                  \n",
    "            #          stddev = 0.1,                                                                                                              \n",
    "            #          shape = [batch_size,]                                                                                                      \n",
    "            #       )                                                                                                                              \n",
    "            #    ),                                                                                                                                 \n",
    "            #    1.0-tf.math.abs(                                                                                                                   \n",
    "            #        tf.random.normal(                                                                                                              \n",
    "            #          mean=0.0,                                                                                                                  \n",
    "            #          stddev = 0.1,                                                                                                              \n",
    "            #          shape = [batch_size,]                                                                                                      \n",
    "            #        )                                                                                                                              \n",
    "            #    ),                                                                                                                                 \n",
    "            #   ],                                                                                                                                     \n",
    "            #   axis=0,                                                                                                                                \n",
    "            # )                          \n",
    "            #in order to discourage the network from collapsing into poor equilibria. I'll talk about that in the next section\n",
    "            #make sure the classifier is trainable (it will be deactivated later, so each loop we want to activate it again)\n",
    "            classifier.trainable=True\n",
    "            classifier.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "            #Actually train the classifier on the batch after all the setup!\n",
    "            classifier.train_on_batch(x_fake_and_real, y1)\n",
    "\n",
    "            #Okay, now we need to train the generator, the idea is, when we feed the entire generator+classifier chain noise,\n",
    "            #The classifier should rate everything a 1, i.e. we think the fake images are genuine data\n",
    "            #So generate some new noise, and 1 labels\n",
    "            noise = tf.random.normal(shape=[batch_size, input_coding_size])\n",
    "            y2 = tf.ones((batch_size,))\n",
    "            # Now we need to avoid training the classifier while trying to train the generator\n",
    "            # We don't want to train it one direction then the opposite\n",
    "            classifier.trainable=False\n",
    "            gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "            gan.train_on_batch(noise, y2)\n",
    "    return gan\n",
    "\n",
    "trained_gan = train_gan(gan, zerobias_gan_dataset, input_coding_size=32, n_epochs=1, batch_size=32)\n",
    "\n",
    "#The classifier and generator can be split off into seperate models\n",
    "#The classifier can be used for anomaly detection by evaluating on datasets as usual\n",
    "#Depending on what you want to do, you can find a use for the generator too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2874f8e-5b45-452d-aecf-fc2b2972b515",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks are an interesting idea, and have some great upsides (a direct classifier trained to do almost exactly the task we are after, a free model that does generative stuff, etc.) but of course they are not without their downsides. The big one is the training loop, which has some problems that stem from game theory. Because these two networks are competing, they can end up in what is called a [Nash Equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium). A Nash Equilibrium is a scenario where neither network stands to gain from changing anymore, if the generator changes it will not fool the classifier any more than it already does, and potentially will become worse, and the classifier cannot be any better on the data it is seeing than it already is. Note, that being in this state does not guarantee that the generated images are any good, nor that the classifier is very accurate to our underlying dataset! This is also called a \"mode collapse\"\n",
    "\n",
    "There are some techniques to try and get around this. One is [SpectralNormalization](https://keras.io/api/layers/preprocessing_layers/numerical/spectral_normalization/) of layers. Another is adding some \"fuzz\" or \"jitter\" to the labels of the dataset (i.e. not using 0 or 1, but removing or adding a tiny bit to each) to try and force the networks out of stable states.\n",
    "\n",
    "We won't have time to explore them here. That's homework, as is checking out the classifier's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add8897-d7d2-47ff-aa18-9bd7dcb5d837",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "\n",
    "Barring some kind of LLM based autoencoder, we've covered a lot of the basics of most of the modern anomaly detection neural network methods. The only remaining major technique to cover is Graph Neural Networks. We'll talk about those in the next exercise if we get time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
